# ğŸ§ª unsloth-finetune-playground

This repo is my personal playground for experimenting with [Unsloth](https://github.com/unslothai/unsloth), a lightweight and blazing-fast framework for fine-tuning large language models (LLMs) like LLaMA and Mistral.

> ğŸš§ This project is currently for learning & testing purposes only. Expect messy code and random experiments!

---

## ğŸ¯ Goals

- âœ… Learn how to fine-tune open-source LLMs with Unsloth
- âœ… Try out QLoRA and LoRA fine-tuning
- âœ… Test different dataset formats
- âœ… Explore model performance with minimal compute

---

## ğŸ“† Setup

Install requirements:

```bash
pip install -U unsloth transformers datasets accelerate
```

GPU (with CUDA) is highly recommended.

---

## ğŸ“ Folder Structure

```bash
.
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ instruction_tuning.py
â”‚   â”œâ”€â”€ classification_finetune.py
â”‚   â””â”€â”€ llama3_qlora_demo.ipynb
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_dataset.json
â””â”€â”€ README.md
```

---

## ğŸ§ª Experiments

| Model       | Dataset         | Notes                      |
|-------------|------------------|-----------------------------|
| LLaMA 2 7B  | Alpaca-style     | Basic instruction tuning   |
| Mistral 7B  | Sentiment sample | Simple classification test |

---

## ğŸ“š References

- [Unsloth GitHub](https://github.com/unslothai/unsloth)
- [LoRA Paper (2021)](https://arxiv.org/abs/2106.09685)
- [QLoRA Paper (2023)](https://arxiv.org/abs/2305.14314)

---

## ğŸ§‘â€ğŸ’» Author

Kevin, AI graduate student @ NYCU (currently studying)  
Practicing LLM fine-tuning for fun and learning.

